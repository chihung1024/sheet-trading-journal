import pandas as pd
import numpy as np
import logging
import pytz
from collections import deque, defaultdict
from datetime import datetime, timedelta
from pyxirr import xirr
from ..models import PortfolioSnapshot, PortfolioSummary, HoldingPosition, DividendRecord, PortfolioGroupData
from ..config import BASE_CURRENCY, DEFAULT_FX_RATE
from .transaction_analyzer import TransactionAnalyzer, PositionSnapshot
from .daily_pnl_helper import DailyPnLHelper
from .currency_detector import CurrencyDetector  # [v2.48] è‡ªåŠ¨è´§å¸è¯†åˆ«
from .validator import PortfolioValidator  # [v2.48] è‡ªåŠ¨éªŒè¯

# å–å¾— logger å¯¦ä¾‹
logger = logging.getLogger(__name__)

class PortfolioCalculator:
    def __init__(self, transactions_df, market_client, benchmark_ticker="SPY", api_client=None):
        """
        åˆå§‹åŒ–è¨ˆç®—å™¨
        :param transactions_df: äº¤æ˜“ç´€éŒ„ DataFrame
        :param market_client: å¸‚å ´æ•¸æ“šå®¢æˆ¶ç«¯
        :param benchmark_ticker: åŸºæº–æ¨™çš„ä»£ç¢¼ (ä¾‹å¦‚ 'SPY', 'QQQ', '0050.TW')
        :param api_client: [v2.53] API å®¢æˆ¶ç«¯ï¼Œç”¨æ–¼åˆªé™¤é‡è¤‡/è¡çªè¨˜éŒ„
        """
        self.df = transactions_df
        self.market = market_client
        self.benchmark_ticker = benchmark_ticker
        self.api_client = api_client  # [v2.53] æ–°å¢
        self.pnl_helper = DailyPnLHelper()
        self.currency_detector = CurrencyDetector()  # [v2.48] æ–°å¢
        self.validator = PortfolioValidator()  # [v2.48] æ–°å¢
        
        # [v2.53] é‡è¤‡é…æ¯æª¢æ¸¬çµæœ
        self.duplicate_div_ids = set()  # [v2.53 Fix] éœ€è¦åœ¨è¨˜æ†¶é«”ä¸­å¿½ç•¥çš„é‡è¤‡è¨˜éŒ„ID
        self.conflict_div_info = {}  # è¡çªé…æ¯è©³æƒ…: {div_key: [record_ids]} (å…¨éƒ¨åˆªé™¤)

    def _is_taiwan_stock(self, symbol):
        """[v2.48] åˆ¤æ–­æ˜¯å¦ç‚ºå°è‚¡(ä¸éœ€åŒ¯ç‡è½‰æ›)"""
        return self.currency_detector.is_base_currency(symbol)

    def _get_effective_fx_rate(self, symbol, fx_rate):
        """[v2.48] æ ¹æ“šæ¨™çš„å–å¾—æœ‰æ•ˆåŒ¯ç‡"""
        return self.currency_detector.get_fx_multiplier(symbol, fx_rate)
    
    def _is_us_market_open(self, tw_datetime):
        """
        [v2.52] åˆ¤æ–­ç¾è‚¡æ˜¯å¦é–‹ç›¤ (å°ç£æ™‚é–“)
        ç°¡åŒ–é‚è¼¯ï¼š
        - é€±æœ«ï¼šä¸é–‹ç›¤
        - äº¤æ˜“æ™‚é–“ï¼šç´„ 21:30/22:30 è‡³ éš”æ—¥ 04:00/05:00
        - é€™è£¡ä½¿ç”¨ 22:00 - 05:00 ä½œç‚ºé€šç”¨åˆ¤æ–·å€é–“
        """
        tw_hour = tw_datetime.hour
        tw_weekday = tw_datetime.weekday()
        
        # é€±æœ«ä¸é–‹ç›¤
        if tw_weekday >= 5:
            return False
        
        # ç°¡åŒ–åˆ¤æ–·ï¼š22:00 ä¹‹å¾Œåˆ°éš”å¤© 05:00 è¦–ç‚ºç›¤ä¸­
        if tw_hour >= 22 or tw_hour < 5:
            return True
        
        return False

    def _get_asset_effective_price_and_fx(self, symbol, target_date, current_fx):
        """
        [v2.52 å¾¹åº•ä¿®å¾©] ç¢ºä¿åƒ¹æ ¼èˆ‡åŒ¯ç‡æ™‚é»åš´æ ¼ä¸€è‡´
        
        ä¿®å¾©é‚è¼¯ï¼š
        1. æ­·å²æ—¥æœŸï¼šåƒ¹æ ¼å’ŒåŒ¯ç‡éƒ½ä½¿ç”¨è©²æ—¥æœŸçš„æ”¶ç›¤æ•¸æ“š
        2. ä»Šå¤© (ç¾è‚¡æœªé–‹)ï¼šåƒ¹æ ¼ç”¨æ˜¨å¤©æ”¶ç›¤ï¼Œä½†åŒ¯ç‡ä½¿ç”¨ã€ä»Šæ—¥å³æ™‚ã€‘(current_fx)
           - ä¿®æ­£é‡é»ï¼šç¢ºä¿è³‡ç”¢åƒ¹å€¼åæ˜ ä»Šæ—¥å°å¹£æ³¢å‹•ï¼Œå³ä¾¿ç¾è‚¡å°šæœªé–‹ç›¤
        3. ä»Šå¤© (ç¾è‚¡ç›¤ä¸­/æ”¶ç›¤)ï¼šåƒ¹æ ¼å’ŒåŒ¯ç‡éƒ½ç”¨ä»Šå¤©å³æ™‚æ•¸æ“š
        """
        is_tw = self._is_taiwan_stock(symbol)
        
        if is_tw:
            # å°è‚¡ç°¡å–®ï¼šä¸éœ€è¦åŒ¯ç‡ï¼Œç›´æ¥ä½¿ç”¨ç›®æ¨™æ—¥æœŸ
            price = self.market.get_price(symbol, pd.Timestamp(target_date))
            return price, 1.0
        
        # === ç¾è‚¡é‚è¼¯ ===
        tw_now = datetime.now(self.pnl_helper.tz_tw)
        today = tw_now.date()
        
        # æƒ…æ³ A: æ­·å²æ—¥æœŸ (æ¯”ä»Šå¤©æ—©)
        if target_date < today:
            price = self.market.get_price(symbol, pd.Timestamp(target_date))
            try:
                # âœ… é—œéµï¼šæ­·å²æ—¥æœŸå¿…é ˆå¾æ­·å²åºåˆ—å–å€¼ï¼Œåš´æ ¼å°é½Šç•¶æ—¥æ­·å²åŒ¯ç‡
                fx_to_use = self.market.fx_rates.asof(pd.Timestamp(target_date))
                if pd.isna(fx_to_use):
                    fx_to_use = DEFAULT_FX_RATE
            except:
                fx_to_use = DEFAULT_FX_RATE
            
            return price, self._get_effective_fx_rate(symbol, fx_to_use)
        
        # æƒ…æ³ B: ä»Šå¤©çš„æ•¸æ“š (target_date == today)
        us_open = self._is_us_market_open(tw_now)
        
        if not us_open:
            # âœ… ç¾è‚¡æœªé–‹ç›¤ï¼š
            # åƒ¹æ ¼ï¼šå›é€€åˆ°ã€Œå‰ä¸€äº¤æ˜“æ—¥ã€çš„æ”¶ç›¤åƒ¹
            # åŒ¯ç‡ï¼šä½¿ç”¨ã€ä»Šæ—¥å³æ™‚åŒ¯ç‡ (current_fx)ã€‘
            # çµæœï¼šè³‡ç”¢åƒ¹å€¼æœƒéš¨ä»Šæ—¥å°å¹£åŒ¯ç‡æ³¢å‹•ï¼Œç¬¦åˆã€Œç¾è‚¡å°šæœªé–‹ç›¤ï¼Œä½†è³‡ç”¢å—åŒ¯ç‡å½±éŸ¿ã€çš„é‚è¼¯
            prev_date = today - timedelta(days=1)
            while prev_date.weekday() >= 5:
                prev_date -= timedelta(days=1)
            
            price = self.market.get_price(symbol, pd.Timestamp(prev_date))
            
            # é€™è£¡ä½¿ç”¨ current_fx (å³æ™‚åŒ¯ç‡)ï¼Œè€Œä¸æ˜¯æ­·å²åŒ¯ç‡
            fx_to_use = current_fx
            
            logger.debug(f"[v2.52] {symbol} ç¾è‚¡æœªé–‹: ä½¿ç”¨æ˜¨æ—¥({prev_date})åƒ¹æ ¼ ({price}) x ä»Šæ—¥å³æ™‚åŒ¯ç‡ ({fx_to_use:.4f})")
            return price, self._get_effective_fx_rate(symbol, fx_to_use)
        
        else:
            # âœ… ç¾è‚¡ç›¤ä¸­/å·²é–‹ç›¤ï¼šåƒ¹æ ¼å’ŒåŒ¯ç‡éƒ½ç”¨ä»Šå¤©å³æ™‚
            price = self.market.get_price(symbol, pd.Timestamp(today))
            fx_to_use = current_fx  # ä½¿ç”¨å‚³å…¥çš„å³æ™‚åŒ¯ç‡
            
            logger.debug(f"[v2.52] {symbol} ç¾è‚¡ç›¤ä¸­: ä½¿ç”¨ä»Šæ—¥å³æ™‚åƒ¹æ ¼ ({price}) x ä»Šæ—¥å³æ™‚åŒ¯ç‡ ({fx_to_use:.4f})")
            return price, self._get_effective_fx_rate(symbol, fx_to_use)

    def _detect_and_remove_duplicate_dividends(self):
        """
        [v2.53 Fix] æª¢æ¸¬é‡è¤‡çš„é…æ¯è¨˜éŒ„ä¸¦å¾ DataFrame ä¸­ç§»é™¤
        
        é—œéµä¿®å¾©ï¼š
        1. æª¢æ¸¬åˆ°é‡è¤‡å¾Œï¼Œç«‹å³å¾ self.df ä¸­ç§»é™¤é‡è¤‡è¨˜éŒ„
        2. åŒæ™‚è¿”å›éœ€è¦å¾è³‡æ–™åº«åˆªé™¤çš„ ID
        
        é€™æ¨£ç¢ºä¿ï¼š
        - è¨ˆç®—æ™‚ä½¿ç”¨çš„ DataFrame å·²ç¶“ä¸åŒ…å«é‡è¤‡è¨˜éŒ„
        - è³‡æ–™åº«ä¹Ÿæœƒè¢«åŒæ­¥æ¸…ç†
        
        è¦å‰‡ï¼š
        1. åŒä¸€è‚¡ç¥¨åŒä¸€å¤©æœ‰å¤šç­† DIV è¨˜éŒ„
        2. å¦‚æœæ•¸æ“šå®Œå…¨ç›¸åŒï¼ˆé‡‘é¡ã€æ•¸é‡ä¸€è‡´ï¼‰â†’ ä¿ç•™ç¬¬ä¸€ç­†ï¼Œç§»é™¤å…¶ä»–
        3. å¦‚æœæ•¸æ“šä¸åŒ â†’ æ¨™è¨˜ç‚ºè¡çªï¼Œç§»é™¤æ‰€æœ‰è¨˜éŒ„å¾Œé€€å›å¾…ç¢ºèª
        
        è¿”å›ï¼š(ids_to_delete_from_db, conflict_info)
        """
        logger.info("[v2.53] é–‹å§‹æª¢æ¸¬ä¸¦ç§»é™¤é‡è¤‡é…æ¯è¨˜éŒ„...")
        
        if self.df.empty:
            return set(), {}
        
        div_txs = self.df[self.df['Type'] == 'DIV'].copy()
        if div_txs.empty:
            logger.info("[v2.53] ç„¡é…æ¯è¨˜éŒ„ï¼Œè·³éæª¢æ¸¬")
            return set(), {}
        
        # ç¢ºä¿æœ‰ id æ¬„ä½
        if 'id' not in div_txs.columns:
            logger.warning("[v2.53] é…æ¯è¨˜éŒ„ç¼ºå°‘ 'id' æ¬„ä½ï¼Œç„¡æ³•é€²è¡Œé‡è¤‡æª¢æ¸¬")
            return set(), {}
        
        # æŒ‰ symbol + date åˆ†çµ„
        div_txs['date_str'] = div_txs['Date'].dt.strftime('%Y-%m-%d')
        div_txs['div_key'] = div_txs['Symbol'] + '_' + div_txs['date_str']
        
        grouped = div_txs.groupby('div_key')
        
        ids_to_remove_from_memory = []  # å¾ DataFrame ç§»é™¤
        ids_to_delete_from_db = set()    # å¾è³‡æ–™åº«åˆªé™¤
        conflict_info = {}
        
        for div_key, group in grouped:
            if len(group) <= 1:
                continue  # åªæœ‰ä¸€ç­†ï¼Œæ­£å¸¸
            
            logger.warning(f"[v2.53] æª¢æ¸¬åˆ° {div_key} æœ‰ {len(group)} ç­†é…æ¯è¨˜éŒ„")
            
            # æª¢æŸ¥æ•¸æ“šæ˜¯å¦ç›¸åŒ
            first_row = group.iloc[0]
            all_same = True
            
            for idx, row in group.iterrows():
                qty_diff = abs(row['Qty'] - first_row['Qty'])
                price_diff = abs(row['Price'] - first_row['Price'])
                
                if qty_diff > 1e-4 or price_diff > 1e-4:
                    all_same = False
                    logger.warning(f"  è¨˜éŒ„ {row['id']}: Qty={row['Qty']}, Price={row['Price']} (èˆ‡ç¬¬ä¸€ç­†ä¸åŒ)")
                else:
                    logger.info(f"  è¨˜éŒ„ {row['id']}: Qty={row['Qty']}, Price={row['Price']} (èˆ‡ç¬¬ä¸€ç­†ç›¸åŒ)")
            
            if all_same:
                # æ•¸æ“šç›¸åŒï¼šä¿ç•™ç¬¬ä¸€ç­†ï¼Œç§»é™¤å…¶ä»–
                keep_id = group.iloc[0]['id']
                logger.info(f"  âœ“ ä¿ç•™è¨˜éŒ„ {keep_id}")
                
                for idx, row in group.iloc[1:].iterrows():
                    ids_to_remove_from_memory.append(idx)  # DataFrame index
                    ids_to_delete_from_db.add(row['id'])   # è³‡æ–™åº« ID
                    logger.info(f"  ğŸ—‘ï¸ ç§»é™¤é‡è¤‡è¨˜éŒ„ {row['id']}")
            else:
                # æ•¸æ“šä¸åŒï¼šæ¨™è¨˜ç‚ºè¡çªï¼Œç§»é™¤æ‰€æœ‰è¨˜éŒ„
                conflict_ids = group['id'].tolist()
                conflict_info[div_key] = conflict_ids
                logger.error(f"  âœ— {div_key} çš„å¤šç­†è¨˜éŒ„æ•¸æ“šä¸ä¸€è‡´ï¼Œæ¨™è¨˜ç‚ºè¡çªï¼")
                logger.error(f"    å°‡ç§»é™¤æ‰€æœ‰è¨˜éŒ„: {conflict_ids}")
                
                # å¾ DataFrame ç§»é™¤æ‰€æœ‰è¡çªè¨˜éŒ„
                for idx, row in group.iterrows():
                    ids_to_remove_from_memory.append(idx)
        
        # ğŸ”¥ é—œéµï¼šå¾ self.df ä¸­ç§»é™¤é‡è¤‡å’Œè¡çªè¨˜éŒ„
        if ids_to_remove_from_memory:
            before_count = len(self.df)
            self.df = self.df.drop(ids_to_remove_from_memory)
            after_count = len(self.df)
            logger.info(f"[v2.53] âœ“ å·²å¾è¨˜æ†¶é«”ä¸­ç§»é™¤ {before_count - after_count} ç­†è¨˜éŒ„")
            logger.info(f"[v2.53] âœ“ è¨ˆç®—å°‡ä½¿ç”¨ä¹¾æ·¨çš„æ•¸æ“š (å…± {after_count} ç­†)")
        
        # åŒæ™‚è¨˜éŒ„éœ€è¦åœ¨è¨ˆç®—æ™‚å¿½ç•¥çš„ IDï¼ˆé›™ä¿éšªï¼‰
        self.duplicate_div_ids = ids_to_delete_from_db.copy()
        
        if ids_to_delete_from_db:
            logger.info(f"[v2.53] æª¢æ¸¬å®Œæˆï¼šå°‡å¾è³‡æ–™åº«åˆªé™¤ {len(ids_to_delete_from_db)} ç­†é‡è¤‡è¨˜éŒ„")
        if conflict_info:
            logger.error(f"[v2.53] è­¦å‘Šï¼šç™¼ç¾ {len(conflict_info)} å€‹é…æ¯è¡çªéœ€è¦è™•ç†")
        
        if not ids_to_delete_from_db and not conflict_info:
            logger.info("[v2.53] æª¢æ¸¬å®Œæˆï¼šæœªç™¼ç¾é‡è¤‡æˆ–è¡çª")
        
        return ids_to_delete_from_db, conflict_info

    def _delete_records_from_database(self, ids_to_delete, record_type="é‡è¤‡"):
        """
        [v2.53] å¾è³‡æ–™åº«åˆªé™¤è¨˜éŒ„
        """
        if not ids_to_delete:
            return
        
        if not self.api_client:
            logger.error(f"[v2.53] ç„¡æ³•åˆªé™¤{record_type}è¨˜éŒ„ï¼šapi_client æœªæä¾›")
            return
        
        logger.info(f"[v2.53] é–‹å§‹å¾è³‡æ–™åº«åˆªé™¤ {len(ids_to_delete)} ç­†{record_type}è¨˜éŒ„...")
        
        # æ‰¹é‡åˆªé™¤
        result = self.api_client.delete_records(list(ids_to_delete))
        
        if result['success'] > 0:
            logger.info(f"[v2.53] âœ“ æˆåŠŸå¾è³‡æ–™åº«åˆªé™¤ {result['success']} ç­†{record_type}è¨˜éŒ„")
        
        if result['failed'] > 0:
            logger.error(f"[v2.53] âœ— åˆªé™¤å¤±æ•— {result['failed']} ç­†: {result['failed_ids']}")

    def run(self):
        """åŸ·è¡Œå¤šç¾¤çµ„æŠ•è³‡çµ„åˆè¨ˆç®—ä¸»æµç¨‹ (v2.53 Fix: è¨˜æ†¶é«”æ¸…ç†)"""
        logger.info(f"=== é–‹å§‹åŸ·è¡Œå¤šç¾¤çµ„æŠ•è³‡çµ„åˆè¨ˆç®— (åŸºæº–: {self.benchmark_ticker}) ===")
        
        # [v2.53 Fix] æª¢æ¸¬ä¸¦ç«‹å³å¾ DataFrame ä¸­ç§»é™¤é‡è¤‡è¨˜éŒ„
        ids_to_delete, self.conflict_div_info = self._detect_and_remove_duplicate_dividends()
        
        # [v2.53] å¾è³‡æ–™åº«åˆªé™¤é‡è¤‡è¨˜éŒ„
        self._delete_records_from_database(ids_to_delete, "é‡è¤‡")
        
        # [v2.53] å¾è³‡æ–™åº«åˆªé™¤è¡çªè¨˜éŒ„
        if self.conflict_div_info:
            all_conflict_ids = []
            for div_key, record_ids in self.conflict_div_info.items():
                all_conflict_ids.extend(record_ids)
            self._delete_records_from_database(all_conflict_ids, "è¡çª")
        
        # [v2.52] å„ªå…ˆä½¿ç”¨ market_data ä¸­çš„å³æ™‚åŒ¯ç‡
        current_fx = DEFAULT_FX_RATE
        if hasattr(self.market, 'realtime_fx_rate') and self.market.realtime_fx_rate:
            current_fx = self.market.realtime_fx_rate
            logger.info(f"ä½¿ç”¨å³æ™‚åŒ¯ç‡é€²è¡Œè¨ˆç®—: {current_fx:.4f}")
        elif not self.market.fx_rates.empty:
            current_fx = float(self.market.fx_rates.iloc[-1])
            logger.info(f"ä½¿ç”¨æ­·å²æ”¶ç›¤åŒ¯ç‡é€²è¡Œè¨ˆç®— (ç„¡å³æ™‚æ•¸æ“š): {current_fx:.4f}")

        if self.df.empty:
            logger.warning("ç„¡äº¤æ˜“ç´€éŒ„,ç”¢ç”Ÿç©ºå¿«ç…§ä»¥é‡ç½®æ•¸æ“šã€‚")
            empty_summary = PortfolioSummary(
                total_value=0, invested_capital=0, total_pnl=0, 
                twr=0, xirr=0, realized_pnl=0, benchmark_twr=0, daily_pnl_twd=0
            )
            return PortfolioSnapshot(
                updated_at=datetime.now().strftime("%Y-%m-%d %H:%M"),
                base_currency=BASE_CURRENCY,
                exchange_rate=round(current_fx, 2),
                summary=empty_summary,
                holdings=[],
                history=[],
                pending_dividends=[],
                groups={"all": PortfolioGroupData(summary=empty_summary, holdings=[], history=[], pending_dividends=[])}
            )
            
        # [v2.46] å…¨åŸŸå¾©æ¬Šé è™•ç†
        self._back_adjust_transactions_global()
        
        # [v2.40] ç²å–å¸‚å ´ç‹€æ…‹
        current_stage, stage_desc = self.pnl_helper.get_market_stage()
        logger.info(f"ç•¶å‰å¸‚å ´ç‹€æ…‹: {current_stage} ({stage_desc})")

        all_tags = set()
        for tags_str in self.df['Tag'].dropna().unique():
            if not tags_str: 
                continue
            split_tags = [t.strip() for t in tags_str.replace(';', ',').split(',') if t.strip()]
            all_tags.update(split_tags)
        
        groups_to_calc = ['all'] + sorted(list(all_tags))
        logger.info(f"è­˜åˆ¥åˆ°çš„ç¾¤çµ„: {groups_to_calc}")

        final_groups_data = {}
        
        for group_name in groups_to_calc:
            logger.info(f"æ­£åœ¨è¨ˆç®—ç¾¤çµ„: {group_name}")
            
            if group_name == 'all':
                group_df = self.df.copy()
            else:
                mask = self.df['Tag'].apply(
                    lambda x: group_name in [t.strip() for t in (x or '').replace(';', ',').split(',')]
                )
                group_df = self.df[mask].copy()
            
            if group_df.empty:
                logger.warning(f"ç¾¤çµ„ {group_name} ç„¡äº¤æ˜“ç´€éŒ„,è·³é")
                continue

            group_start_date = group_df['Date'].min()
            group_end_date = datetime.now()
            group_date_range = pd.date_range(start=group_start_date, end=group_end_date, freq='D').normalize()
            
            logger.info(f"[ç¾¤çµ„:{group_name}] æ—¥æœŸç¯„åœ: {group_start_date.strftime('%Y-%m-%d')} ~ {group_end_date.strftime('%Y-%m-%d')}")

            group_result = self._calculate_single_portfolio(group_df, group_date_range, current_fx, group_name, current_stage)
            final_groups_data[group_name] = group_result

        all_data = final_groups_data.get('all')
        if not all_data:
            logger.error("ç„¡æ³•ç”¢å‡º 'all' ç¾¤çµ„çš„ç¸½é«”æ•¸æ“š")
            return None
        
        return PortfolioSnapshot(
            updated_at=datetime.now().strftime("%Y-%m-%d %H:%M"),
            base_currency=BASE_CURRENCY,
            exchange_rate=round(current_fx, 2),
            summary=all_data.summary,
            holdings=all_data.holdings,
            history=all_data.history,
            pending_dividends=all_data.pending_dividends,
            groups=final_groups_data
        )

    def _back_adjust_transactions_global(self):
        """[v2.48] å…¨åŸŸå¾©æ¬Šè™•ç†"""
        logger.info("æ­£åœ¨é€²è¡Œå…¨åŸŸäº¤æ˜“æ•¸æ“šå¾©æ¬Šè™•ç†...")
        for index, row in self.df.iterrows():
            sym = row['Symbol']
            date = row['Date']
            if row['Type'] not in ['BUY', 'SELL']: 
                continue
            
            is_tw = self._is_taiwan_stock(sym)
            split_factor = self.market.get_transaction_multiplier(sym, date)
            
            if is_tw:
                div_adj_factor = 1.0
            else:
                div_adj_factor = self.market.get_dividend_adjustment_factor(sym, date)
            
            if split_factor != 1.0 or div_adj_factor != 1.0:
                old_qty = row['Qty']
                old_price = row['Price']
                new_qty = old_qty * split_factor
                new_price = (old_price / split_factor) * div_adj_factor
                
                self.df.at[index, 'Qty'] = new_qty
                self.df.at[index, 'Price'] = new_price

    def _get_previous_trading_day(self, date):
        """ç²å–å‰ä¸€å€‹äº¤æ˜“æ—¥(æ’é™¤å‘¨æœ«)"""
        prev_date = date - timedelta(days=1)
        while prev_date.weekday() >= 5:
            prev_date -= timedelta(days=1)
        return prev_date

    def _calculate_single_portfolio(self, df, date_range, current_fx, group_name="unknown", current_stage="CLOSED"):
        """å–®ä¸€ç¾¤çµ„çš„æ ¸å¿ƒè¨ˆç®—é‚è¼¯ (v2.53 Fix: ä½¿ç”¨ä¹¾æ·¨çš„ DataFrame)"""
        
        txn_analyzer = TransactionAnalyzer(df)
        
        holdings = {}
        fifo_queues = {}
        invested_capital = 0.0
        total_realized_pnl_twd = 0.0
        history_data = []
        confirmed_dividends = set()
        dividend_history = []
        xirr_cashflows = []
        
        cumulative_twr_factor = 1.0
        last_market_value_twd = 0.0
        first_benchmark_val_twd = None

        # [v2.53] å»ºç«‹confirmed_dividendsï¼ˆDataFrameå·²ç¶“ä¹¾æ·¨ï¼Œä½†ä¿ç•™éæ¿¾é‚è¼¯ä½œç‚ºé›™ä¿éšªï¼‰
        div_txs = df[df['Type'] == 'DIV'].copy()
        
        for _, row in div_txs.iterrows():
            # [v2.53 Fix] é›™ä¿éšªï¼šå³ä½¿è¨˜æ†¶é«”å·²æ¸…ç†ï¼Œä»æª¢æŸ¥æ˜¯å¦åœ¨å¿½ç•¥åˆ—è¡¨ä¸­
            if 'id' in row and row['id'] in self.duplicate_div_ids:
                logger.debug(f"[v2.53] é›™ä¿éšªï¼šè·³éå·²æ¨™è¨˜çš„é‡è¤‡è¨˜éŒ„ {row['id']}")
                continue
            
            key = f"{row['Symbol']}_{row['Date'].strftime('%Y-%m-%d')}"
            confirmed_dividends.add(key)

        if not df.empty:
            first_tx_date = df['Date'].min()
            prev_trading_day = self._get_previous_trading_day(first_tx_date)
            prev_date_str = prev_trading_day.strftime('%Y-%m-%d')
            
            try:
                prev_fx = self.market.fx_rates.asof(prev_trading_day)
                if pd.isna(prev_fx): prev_fx = DEFAULT_FX_RATE
            except: 
                prev_fx = DEFAULT_FX_RATE
            
            prev_benchmark_p = self.market.get_price(self.benchmark_ticker, prev_trading_day)
            effective_prev_fx = self._get_effective_fx_rate(self.benchmark_ticker, prev_fx)
            prev_benchmark_val_twd = prev_benchmark_p * effective_prev_fx
            
            if first_benchmark_val_twd is None and prev_benchmark_val_twd > 0:
                first_benchmark_val_twd = prev_benchmark_val_twd
            
            history_data.append({
                "date": prev_date_str, 
                "total_value": 0,
                "invested": 0, 
                "net_profit": 0,
                "realized_pnl": 0,
                "unrealized_pnl": 0,
                "twr": 0.0, 
                "benchmark_twr": 0.0,
                "fx_rate": round(prev_fx, 4)
            })
            
            logger.info(f"[ç¾¤çµ„:{group_name}] å·²åœ¨ {prev_date_str} è£œä¸Šè™›æ“¬ 0 è³‡ç”¢è¨˜éŒ„(ç¬¬ä¸€ç­†äº¤æ˜“: {first_tx_date.strftime('%Y-%m-%d')})ã€‚")

        last_fx = current_fx
        
        for d in date_range:
            current_date = d.date()
            
            try:
                fx = self.market.fx_rates.asof(d)
                if pd.isna(fx): fx = DEFAULT_FX_RATE
            except: 
                fx = DEFAULT_FX_RATE
            
            benchmark_p = self.market.get_price(self.benchmark_ticker, d)
            effective_benchmark_fx = self._get_effective_fx_rate(self.benchmark_ticker, fx)
            curr_benchmark_val_twd = benchmark_p * effective_benchmark_fx

            if first_benchmark_val_twd is None and curr_benchmark_val_twd > 0:
                first_benchmark_val_twd = curr_benchmark_val_twd

            daily_txns = df[df['Date'].dt.date == current_date].copy()
            
            if not daily_txns.empty:
                priority_map = {'BUY': 1, 'DIV': 2, 'SELL': 3}
                daily_txns['priority'] = daily_txns['Type'].map(priority_map).fillna(99)
                daily_txns = daily_txns.sort_values(by='priority', kind='stable')
            
            daily_net_cashflow_twd = 0.0
            
            for _, row in daily_txns.iterrows():
                sym = row['Symbol']
                if sym not in holdings:
                    holdings[sym] = {'qty': 0.0, 'cost_basis_usd': 0.0, 'cost_basis_twd': 0.0, 'tag': row['Tag']}
                    fifo_queues[sym] = deque()

                if row['Type'] == 'BUY':
                    effective_fx = self._get_effective_fx_rate(sym, fx)
                    cost_usd = (row['Qty'] * row['Price']) + row['Commission'] + row['Tax']
                    cost_twd = cost_usd * effective_fx
                    holdings[sym]['qty'] += row['Qty']
                    holdings[sym]['cost_basis_usd'] += cost_usd
                    holdings[sym]['cost_basis_twd'] += cost_twd
                    fifo_queues[sym].append({
                        'qty': row['Qty'], 'price': row['Price'], 'cost_total_usd': cost_usd, 
                        'cost_total_twd': cost_twd, 'date': d
                    })
                    invested_capital += cost_twd
                    xirr_cashflows.append({'date': d, 'amount': -cost_twd})
                    daily_net_cashflow_twd += cost_twd

                elif row['Type'] == 'SELL':
                    if not fifo_queues.get(sym) or not fifo_queues[sym]: continue
                    effective_fx = self._get_effective_fx_rate(sym, fx)
                    proceeds_twd = ((row['Qty'] * row['Price']) - row['Commission'] - row['Tax']) * effective_fx
                    remaining = row['Qty']
                    cost_sold_twd = 0.0
                    cost_sold_usd = 0.0
                    while remaining > 1e-6 and fifo_queues[sym]:
                        batch = fifo_queues[sym][0]
                        take = min(remaining, batch['qty'])
                        frac = take / batch['qty']
                        cost_sold_usd += batch['cost_total_usd'] * frac
                        cost_sold_twd += batch['cost_total_twd'] * frac
                        batch['qty'] -= take
                        batch['cost_total_usd'] -= batch['cost_total_usd'] * frac
                        batch['cost_total_twd'] -= batch['cost_total_twd'] * frac
                        remaining -= take
                        if batch['qty'] < 1e-6: fifo_queues[sym].popleft()
                    
                    holdings[sym]['qty'] -= (row['Qty'] - remaining)
                    holdings[sym]['cost_basis_usd'] -= cost_sold_usd
                    holdings[sym]['cost_basis_twd'] -= cost_sold_twd
                    invested_capital -= cost_sold_twd
                    total_realized_pnl_twd += (proceeds_twd - cost_sold_twd)
                    xirr_cashflows.append({'date': d, 'amount': proceeds_twd})
                    daily_net_cashflow_twd -= proceeds_twd

                elif row['Type'] == 'DIV':
                    # [v2.53 Fix] é›™ä¿éšªï¼šæª¢æŸ¥æ˜¯å¦ç‚ºæ‡‰å¿½ç•¥çš„è¨˜éŒ„
                    if 'id' in row and row['id'] in self.duplicate_div_ids:
                        logger.debug(f"[v2.53] è¨ˆç®—æ™‚è·³éé‡è¤‡é…æ¯è¨˜éŒ„: {row['Symbol']} {row['Date'].strftime('%Y-%m-%d')} (ID: {row['id']})")
                        continue
                    
                    effective_fx = self._get_effective_fx_rate(sym, fx)
                    div_twd = row['Price'] * effective_fx
                    total_realized_pnl_twd += div_twd
                    xirr_cashflows.append({'date': d, 'amount': div_twd})
                    daily_net_cashflow_twd -= div_twd

            # [v2.44 å¾©æ¬Šä¿®æ­£] é…æ¯è¨ˆç®—
            date_str = d.strftime('%Y-%m-%d')
            for sym, h_data in holdings.items():
                div_per_share = self.market.get_dividend(sym, d)
                if div_per_share > 0 and h_data['qty'] > 1e-6:
                    effective_fx = self._get_effective_fx_rate(sym, fx)
                    div_key = f"{sym}_{date_str}"
                    
                    # [v2.53] æª¢æŸ¥æ˜¯å¦ç‚ºè¡çªï¼ˆå·²åˆªé™¤çš„é…æ¯ï¼‰
                    if div_key in [k for k in self.conflict_div_info.keys()]:
                        logger.info(f"[v2.53] è·³éè¡çªé…æ¯: {div_key} (å·²åˆªé™¤ï¼Œå°‡é‡æ–°é¡¯ç¤ºåœ¨å¾…ç¢ºèªå€)")
                        is_confirmed = False
                    else:
                        is_confirmed = div_key in confirmed_dividends
                    
                    split_factor = self.market.get_transaction_multiplier(sym, d)
                    shares_at_ex = h_data['qty'] / split_factor
                    
                    total_gross = shares_at_ex * div_per_share
                    total_net_usd = total_gross * 0.7 
                    total_net_twd = total_net_usd * effective_fx

                    dividend_history.append({
                        'symbol': sym, 'ex_date': date_str, 'shares_held': h_data['qty'],
                        'dividend_per_share_gross': div_per_share, 
                        'total_gross': round(total_gross, 2),
                        'total_net_usd': round(total_net_usd, 2),
                        'total_net_twd': round(total_net_twd, 0),
                        'fx_rate': fx, 'status': 'confirmed' if is_confirmed else 'pending'
                    })
                    
                    if not is_confirmed:
                        total_realized_pnl_twd += total_net_twd
                        xirr_cashflows.append({'date': d, 'amount': total_net_twd})
                        daily_net_cashflow_twd -= total_net_twd

            # [v2.52 FIX] è¨ˆç®—å¸‚å€¼æ™‚ä½¿ç”¨ä¿®å¾©å¾Œçš„åƒ¹æ ¼èˆ‡åŒ¯ç‡é¸æ“‡é‚è¼¯
            current_market_value_twd = 0.0
            logging_fx = fx
            
            for sym, h in holdings.items():
                if h['qty'] > 1e-6:
                    price, effective_fx = self._get_asset_effective_price_and_fx(sym, current_date, current_fx)
                    current_market_value_twd += h['qty'] * price * effective_fx
                    logging_fx = effective_fx if not self._is_taiwan_stock(sym) else logging_fx
            
            period_hpr_factor = 1.0
            
            if last_market_value_twd > 1e-9:
                period_hpr_factor = (current_market_value_twd - daily_net_cashflow_twd) / last_market_value_twd
            elif current_market_value_twd > 1e-9 and daily_net_cashflow_twd > 1e-9:
                period_hpr_factor = current_market_value_twd / daily_net_cashflow_twd
            elif current_market_value_twd < 1e-9 and last_market_value_twd < 1e-9:
                period_hpr_factor = 1.0
            
            if not np.isfinite(period_hpr_factor):
                period_hpr_factor = 1.0
            
            cumulative_twr_factor *= period_hpr_factor
            last_market_value_twd = current_market_value_twd
            
            unrealized_pnl = current_market_value_twd - sum(h['cost_basis_twd'] for h in holdings.values() if h['qty'] > 1e-6)
            total_pnl = unrealized_pnl + total_realized_pnl_twd
            
            benchmark_twr = (curr_benchmark_val_twd / first_benchmark_val_twd - 1) * 100 if first_benchmark_val_twd else 0.0

            history_data.append({
                "date": date_str, "total_value": round(current_market_value_twd, 0),
                "invested": round(invested_capital, 0), 
                "net_profit": round(total_pnl, 0),
                "realized_pnl": round(total_realized_pnl_twd, 0),
                "unrealized_pnl": round(unrealized_pnl, 0),
                "twr": round((cumulative_twr_factor - 1) * 100, 2), 
                "benchmark_twr": round(benchmark_twr, 2),
                "fx_rate": round(logging_fx, 4)
            })
            
            last_fx = fx

        # --- [v2.48] æœ€çµ‚å ±è¡¨ç”¢ç”Ÿ & é©—è­‰ ---
        final_holdings = []
        current_holdings_cost_sum = 0.0
        
        effective_date_tw = self.pnl_helper.get_effective_display_date(True)
        effective_date_us = self.pnl_helper.get_effective_display_date(False)
        
        txns_tw_day = df[df['Date'].dt.date == effective_date_tw]
        txns_us_day = df[df['Date'].dt.date == effective_date_us]
        
        active_symbols = set([k for k, v in holdings.items() if v['qty'] > 1e-4])
        active_symbols.update(txns_tw_day['Symbol'].unique())
        active_symbols.update(txns_us_day['Symbol'].unique())

        for sym in active_symbols:
            h = holdings.get(sym, {'qty': 0.0, 'cost_basis_usd': 0.0, 'cost_basis_twd': 0.0, 'tag': None})
            
            is_tw = self._is_taiwan_stock(sym)
            effective_display_date = self.pnl_helper.get_effective_display_date(is_tw)
            
            sym_txs = df[(df['Symbol'] == sym) & (df['Date'].dt.date == effective_display_date)]
            
            if not h['tag'] and not sym_txs.empty:
                tags = sym_txs['Tag'].dropna()
                if not tags.empty:
                    h['tag'] = tags.iloc[0]

            effective_fx = self._get_effective_fx_rate(sym, current_fx)
            
            curr_p = self.market.get_price(sym, pd.Timestamp(effective_display_date))
            prev_date = effective_display_date - timedelta(days=1)
            while prev_date.weekday() >= 5:
                prev_date -= timedelta(days=1)
            prev_p = self.market.get_price(sym, pd.Timestamp(prev_date))
            
            position_snap = txn_analyzer.analyze_today_position(sym, effective_display_date, effective_fx)
            
            realized_pnl_today = position_snap.realized_pnl
            
            base_prev_close = prev_p 
            unrealized_pnl_today = 0.0
            
            if position_snap.qty > 0:
                weighted_base = txn_analyzer.get_base_price_for_pnl(position_snap, base_prev_close)
                unrealized_pnl_today = (curr_p - weighted_base) * position_snap.qty * effective_fx
            
            total_daily_pnl = realized_pnl_today + unrealized_pnl_today
            
            cost = h['cost_basis_twd']
            current_holdings_cost_sum += cost
            mkt_val = h['qty'] * curr_p * effective_fx
            
            daily_change_pct = round((curr_p - prev_p) / prev_p * 100, 2) if prev_p > 0 else 0.0
            
            currency = self.currency_detector.detect(sym)
            
            if h['qty'] > 1e-4 or abs(total_daily_pnl) > 1:
                 final_holdings.append(HoldingPosition(
                    symbol=sym, tag=h['tag'], currency=currency, qty=round(h['qty'], 2),
                    market_value_twd=round(mkt_val, 0), pnl_twd=round(mkt_val - cost, 0),
                    pnl_percent=round((mkt_val - cost) / cost * 100, 2) if cost > 0 else 0,
                    current_price_origin=round(curr_p, 2), avg_cost_usd=round(h['cost_basis_usd'] / h['qty'], 2) if h['qty'] > 0 else 0,
                    prev_close_price=round(prev_p, 2), daily_change_usd=round(curr_p - prev_p, 2),
                    daily_change_percent=daily_change_pct,
                    daily_pl_twd=round(total_daily_pnl, 0)
                ))
        
        final_holdings.sort(key=lambda x: x.market_value_twd, reverse=True)
        
        display_daily_pnl = sum(h.daily_pl_twd for h in final_holdings)
        
        logger.info(f"[ç¾¤çµ„:{group_name}] ç•¶æ—¥æç›Š(æŒè‚¡åŠ ç¸½ v2.48): {display_daily_pnl}")
        
        self.validator.validate_daily_balance(holdings, invested_capital, current_holdings_cost_sum)
        
        xirr_val = 0.0
        if xirr_cashflows:
            curr_val_sum = sum(h.market_value_twd for h in final_holdings)
            xirr_cashflows_calc = xirr_cashflows.copy()
            xirr_cashflows_calc.append({'date': datetime.now(), 'amount': curr_val_sum})
            try:
                xirr_res = xirr([x['date'] for x in xirr_cashflows_calc], [x['amount'] for x in xirr_cashflows_calc])
                xirr_val = round(xirr_res * 100, 2)
            except: pass

        current_total_value = sum(h.market_value_twd for h in final_holdings)
        current_invested = current_holdings_cost_sum
        current_total_pnl = current_total_value - current_invested + total_realized_pnl_twd
        
        summary = PortfolioSummary(
            total_value=round(current_total_value, 0),
            invested_capital=round(current_invested, 0),
            total_pnl=round(current_total_pnl, 0),
            twr=history_data[-1]['twr'] if history_data else 0,
            xirr=xirr_val,
            realized_pnl=round(total_realized_pnl_twd, 0),
            benchmark_twr=history_data[-1]['benchmark_twr'] if history_data else 0,
            daily_pnl_twd=round(display_daily_pnl, 0)
        )
        
        self.validator.validate_twr_calculation(history_data)
        
        return PortfolioGroupData(
            summary=summary, holdings=final_holdings, history=history_data,
            pending_dividends=[DividendRecord(**d) for d in dividend_history if d['status']=='pending']
        )